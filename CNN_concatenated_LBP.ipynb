{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN concatenated LBP ",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harjotsinghparmar/Google-Colab-Deep-Learning/blob/master/CNN_concatenated_LBP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ffGJq9wSZS4-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network\n",
        "\n",
        "In this second exercise-notebook we will play with Convolutional Neural Network (CNN). \n",
        "\n",
        "As you should have seen, a CNN is a feed-forward neural network tipically composed of Convolutional, MaxPooling and Dense layers. \n",
        "\n",
        "If the task implemented by the CNN is a classification task, the last Dense layer should use the **Softmax** activation, and the loss should be the **categorical crossentropy**.\n",
        "\n",
        "Reference: [https://github.com/fchollet/keras/blob/master/examples/cifar10_cnn.py]()"
      ]
    },
    {
      "metadata": {
        "id": "mIjXZOqhZS5B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training the network\n",
        "\n",
        "We will train our network on the **CIFAR10** [dataset](https://www.cs.toronto.edu/~kriz/cifar.html), which contains `50,000` 32x32 color training images, labeled over 10 categories, and 10,000 test images. \n",
        "\n",
        "As this dataset is also included in Keras datasets, we just ask the `keras.datasets` module for the dataset.\n",
        "\n",
        "Training and test images are normalized to lie in the $\\left[0,1\\right]$ interval."
      ]
    },
    {
      "metadata": {
        "id": "26MUGw78ZS5C",
        "colab_type": "code",
        "outputId": "3db03aee-2066-43a5-a019-5a39e4871a39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation, Input, Concatenate\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "nb_classes = 10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "X_train = X_train.astype(\"float32\")\n",
        "X_test = X_test.astype(\"float32\")\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 21s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1gcDKHVZlfnr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## import libraries\n",
        "import os \n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import local_binary_pattern\n",
        "\n",
        "def six_channel_lbp(image_path):\n",
        "    \"\"\"\n",
        "    Takes input as image path and returns six channel numpy array\n",
        "    \n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path,0)\n",
        "    image = (cv2.imread(image_path))\n",
        "    print(image.shape)\n",
        "    for (r,p) in [(i,i*8) for i in range(1,4)]: \n",
        "        lbp = local_binary_pattern(img,p,r, method=\"uniform\")\n",
        "        expanded_lbp = (np.expand_dims(lbp,axis=2))\n",
        "        image = np.dstack((image,expanded_lbp))\n",
        "    return(image)\n",
        "\n",
        "\n",
        "def six_channel_lbp_from_array(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
        "    for (r,p) in [(i,i*8) for i in range(1,3)]: \n",
        "        lbp = local_binary_pattern(gray,p,r, method=\"uniform\")\n",
        "        expanded_lbp = (np.expand_dims(lbp,axis=2))\n",
        "        image = np.dstack((image,expanded_lbp))\n",
        "    return(image)\n",
        "  \n",
        "def six_channel_lbp_hist(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
        "    empty_lbp = []\n",
        "    total_bins = 0\n",
        "    for (r,p) in [(i,i*8) for i in range(1,6)]: \n",
        "        lbp = local_binary_pattern(gray ,p,r, method=\"uniform\")\n",
        "        histogram = np.histogram(lbp,bins = np.arange(p+1))[0]\n",
        "        empty_lbp.extend(histogram)\n",
        "        total_bins = total_bins+p\n",
        "    lbp_hist = np.array(empty_lbp,dtype=np.uint8)\n",
        "    return(lbp_hist,total_bins)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xdISHu_Ultpy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Add lbp channels"
      ]
    },
    {
      "metadata": {
        "id": "lZdKL5ZQlsdY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_lbp = np.asarray([six_channel_lbp_hist(x)[0] for x in X_train])\n",
        "\n",
        "X_test_lbp = np.asarray([six_channel_lbp_hist(x)[0] for x in X_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "msiRCxLsls-J",
        "colab_type": "code",
        "outputId": "a72ec2f3-7f0f-4b87-cd51-6a302d206cc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "rdhksuQJZS5S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Warning: The following cells may be computational Intensive...."
      ]
    },
    {
      "metadata": {
        "id": "2PE3OVXwZS5T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create the cnn + lbp combo\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uq6OP5-vYVQu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers.merge import concatenate\n",
        "def cnn_lbp_model():\n",
        "  #CNN part \n",
        "  input1 = Input(shape = (32,32,3,))\n",
        "    \n",
        "  x = (Conv2D(128, (3, 3), activation='relu', padding='same'))(input1)   \n",
        "  x = (Conv2D(128, (3, 3), activation='relu'))(x)    \n",
        "  x = (MaxPooling2D(pool_size=(2, 2)))(x)\n",
        "  x = (Dropout(0.25))(x)\n",
        "\n",
        "    \n",
        "  x = (Conv2D(128, (3, 3), activation='relu', padding='same'))(x)\n",
        "  x = (Conv2D(128, (3, 3), activation='relu'))(x)\n",
        "  x = (MaxPooling2D(pool_size=(2, 2)))(x)\n",
        "  x = (Dropout(0.25))(x)\n",
        "  x = (Flatten())(x)\n",
        "  \n",
        "  #Concatenate LBP layer\n",
        "  input2 = Input((120,))\n",
        "  conc = concatenate([x,input2])\n",
        "  conc1 = (Dense(512, activation='relu'))(conc)\n",
        "  conc1 = (Dropout(0.5))(conc1)\n",
        "  \n",
        "    \n",
        "  output = (Dense(nb_classes, activation='softmax'))(conc1)\n",
        "  model = Model(inputs = [input1,input2], outputs = output)\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  model.summary()\n",
        "  \n",
        "  return model \n",
        "  \n",
        "  \n",
        "def cnn_model():\n",
        "  #CNN part \n",
        "  input1 = Input(shape = (32,32,3,))\n",
        "    \n",
        "  x = (Conv2D(128, (3, 3), activation='relu', padding='same'))(input1)   \n",
        "  x = (Conv2D(128, (3, 3), activation='relu'))(x)    \n",
        "  x = (MaxPooling2D(pool_size=(2, 2)))(x)\n",
        "  x = (Dropout(0.25))(x)\n",
        "\n",
        "    \n",
        "  x = (Conv2D(128, (3, 3), activation='relu', padding='same'))(x)\n",
        "  x = (Conv2D(128, (3, 3), activation='relu'))(x)\n",
        "  x = (MaxPooling2D(pool_size=(2, 2)))(x)\n",
        "  x = (Dropout(0.25))(x)\n",
        "  x = (Flatten())(x)\n",
        "  \n",
        "  #Concatenate LBP layer\n",
        "\n",
        "  output = (Dense(nb_classes, activation='softmax'))(x)\n",
        "  model = Model(inputs = [input1], outputs = output)\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  model.summary()\n",
        "  \n",
        "  return model \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RNNtxS_-hyQE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-XfkZ_IOZS5Z",
        "colab_type": "code",
        "outputId": "13dfdd75-cc8c-4d00-d61d-7cedf00b1650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = cnn_lbp_model()\n",
        "cnn_model = cnn_model()\n",
        "\n",
        "model.compile(optimizer = 'rmsprop',loss = 'binary_crossentropy',learning_rate = 0.001)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_50 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 32, 32, 128)  3584        input_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 30, 30, 128)  147584      conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling2D) (None, 15, 15, 128)  0           conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 15, 15, 128)  0           max_pooling2d_43[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 15, 15, 128)  147584      dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 13, 13, 128)  147584      conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling2D) (None, 6, 6, 128)    0           conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_67 (Dropout)            (None, 6, 6, 128)    0           max_pooling2d_44[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_22 (Flatten)            (None, 4608)         0           dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "input_51 (InputLayer)           (None, 120)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 4728)         0           flatten_22[0][0]                 \n",
            "                                                                 input_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_74 (Dense)                (None, 512)          2421248     concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_68 (Dropout)            (None, 512)          0           dense_74[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_75 (Dense)                (None, 10)           5130        dropout_68[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 2,872,714\n",
            "Trainable params: 2,872,714\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_52 (InputLayer)        (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_89 (Conv2D)           (None, 32, 32, 128)       3584      \n",
            "_________________________________________________________________\n",
            "conv2d_90 (Conv2D)           (None, 30, 30, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_69 (Dropout)         (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_91 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 13, 13, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_70 (Dropout)         (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_23 (Flatten)         (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 10)                46090     \n",
            "=================================================================\n",
            "Total params: 492,426\n",
            "Trainable params: 492,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fpSHCuiFbmRy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7OsZ7YSSZS5j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('best_model_simple.h5',  # model filename\n",
        "                             monitor='val_loss', # quantity to monitor\n",
        "                             verbose=0, # verbosity - 0 or 1\n",
        "                             save_best_only= True, # The latest best model will not be overwritten\n",
        "                             mode='auto') # The decision to overwrite model is made \n",
        "                                          # automatically depending on the quantity to monitor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MRrW2E78-cID",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SG-XgouIZS5o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', # Better loss function for neural networks\n",
        "              optimizer=Adam(lr=1.0e-4), # Adam optimizer with 1.0e-4 learning rate\n",
        "              metrics = ['accuracy']) # Metrics to be evaluated by the model\n",
        "\n",
        "cnn_model.compile(loss='categorical_crossentropy', # Better loss function for neural networks\n",
        "              optimizer=Adam(lr=1.0e-4), # Adam optimizer with 1.0e-4 learning rate\n",
        "              metrics = ['accuracy']) # Metrics to be evaluated by the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oA6UH-xpZS5t",
        "colab_type": "code",
        "outputId": "d4668ce5-2513-4c5b-d7e9-347d94408bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3468
        }
      },
      "cell_type": "code",
      "source": [
        "model_details = model.fit([X_train,X_train_lbp], Y_train,\n",
        "                    batch_size = 128, # number of samples per gradient update\n",
        "                    epochs =5000, # number of iterations\n",
        "                    validation_data= ([X_test,X_test_lbp], Y_test),\n",
        "                    callbacks=[checkpoint],\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5000\n",
            "50000/50000 [==============================] - 35s 706us/step - loss: 3.1972 - acc: 0.2027 - val_loss: 1.8595 - val_acc: 0.3248\n",
            "Epoch 2/5000\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 1.8787 - acc: 0.3069 - val_loss: 1.6661 - val_acc: 0.4145\n",
            "Epoch 3/5000\n",
            "50000/50000 [==============================] - 33s 652us/step - loss: 1.7170 - acc: 0.3715 - val_loss: 1.5205 - val_acc: 0.4596\n",
            "Epoch 4/5000\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 1.6123 - acc: 0.4162 - val_loss: 1.4085 - val_acc: 0.4913\n",
            "Epoch 5/5000\n",
            "50000/50000 [==============================] - 33s 655us/step - loss: 1.5253 - acc: 0.4502 - val_loss: 1.3425 - val_acc: 0.5190\n",
            "Epoch 6/5000\n",
            "50000/50000 [==============================] - 33s 655us/step - loss: 1.4694 - acc: 0.4700 - val_loss: 1.3119 - val_acc: 0.5250\n",
            "Epoch 7/5000\n",
            "50000/50000 [==============================] - 33s 655us/step - loss: 1.4189 - acc: 0.4904 - val_loss: 1.2738 - val_acc: 0.5385\n",
            "Epoch 8/5000\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 1.3787 - acc: 0.5078 - val_loss: 1.2231 - val_acc: 0.5724\n",
            "Epoch 9/5000\n",
            "50000/50000 [==============================] - 33s 655us/step - loss: 1.3330 - acc: 0.5239 - val_loss: 1.1852 - val_acc: 0.5793\n",
            "Epoch 10/5000\n",
            "50000/50000 [==============================] - 33s 655us/step - loss: 1.2985 - acc: 0.5366 - val_loss: 1.1666 - val_acc: 0.5895\n",
            "Epoch 11/5000\n",
            "50000/50000 [==============================] - 33s 656us/step - loss: 1.2630 - acc: 0.5505 - val_loss: 1.1171 - val_acc: 0.6117\n",
            "Epoch 12/5000\n",
            "50000/50000 [==============================] - 33s 655us/step - loss: 1.2266 - acc: 0.5638 - val_loss: 1.0980 - val_acc: 0.6147\n",
            "Epoch 13/5000\n",
            "50000/50000 [==============================] - 33s 653us/step - loss: 1.1919 - acc: 0.5772 - val_loss: 1.0566 - val_acc: 0.6298\n",
            "Epoch 14/5000\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 1.1643 - acc: 0.5859 - val_loss: 1.0509 - val_acc: 0.6368\n",
            "Epoch 15/5000\n",
            "50000/50000 [==============================] - 33s 655us/step - loss: 1.1289 - acc: 0.6025 - val_loss: 1.0283 - val_acc: 0.6443\n",
            "Epoch 16/5000\n",
            "50000/50000 [==============================] - 33s 652us/step - loss: 1.1092 - acc: 0.6101 - val_loss: 1.0052 - val_acc: 0.6580\n",
            "Epoch 17/5000\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 1.0825 - acc: 0.6181 - val_loss: 0.9839 - val_acc: 0.6593\n",
            "Epoch 18/5000\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 1.0495 - acc: 0.6288 - val_loss: 0.9633 - val_acc: 0.6692\n",
            "Epoch 19/5000\n",
            "50000/50000 [==============================] - 33s 655us/step - loss: 1.0236 - acc: 0.6400 - val_loss: 0.9404 - val_acc: 0.6770\n",
            "Epoch 20/5000\n",
            "50000/50000 [==============================] - 33s 656us/step - loss: 1.0088 - acc: 0.6439 - val_loss: 0.9315 - val_acc: 0.6778\n",
            "Epoch 21/5000\n",
            "50000/50000 [==============================] - 33s 653us/step - loss: 0.9836 - acc: 0.6540 - val_loss: 0.9061 - val_acc: 0.6894\n",
            "Epoch 22/5000\n",
            "50000/50000 [==============================] - 33s 652us/step - loss: 0.9539 - acc: 0.6643 - val_loss: 0.8881 - val_acc: 0.6925\n",
            "Epoch 23/5000\n",
            "50000/50000 [==============================] - 33s 653us/step - loss: 0.9390 - acc: 0.6692 - val_loss: 0.8873 - val_acc: 0.6921\n",
            "Epoch 24/5000\n",
            "50000/50000 [==============================] - 33s 656us/step - loss: 0.9159 - acc: 0.6767 - val_loss: 0.8735 - val_acc: 0.6972\n",
            "Epoch 25/5000\n",
            "50000/50000 [==============================] - 33s 655us/step - loss: 0.8939 - acc: 0.6848 - val_loss: 0.8624 - val_acc: 0.7039\n",
            "Epoch 26/5000\n",
            "50000/50000 [==============================] - 33s 655us/step - loss: 0.8755 - acc: 0.6921 - val_loss: 0.8623 - val_acc: 0.7009\n",
            "Epoch 27/5000\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 0.8551 - acc: 0.6990 - val_loss: 0.8714 - val_acc: 0.6983\n",
            "Epoch 28/5000\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 0.8353 - acc: 0.7054 - val_loss: 0.8313 - val_acc: 0.7161\n",
            "Epoch 29/5000\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 0.8233 - acc: 0.7093 - val_loss: 0.8195 - val_acc: 0.7194\n",
            "Epoch 30/5000\n",
            "50000/50000 [==============================] - 33s 653us/step - loss: 0.8026 - acc: 0.7160 - val_loss: 0.8099 - val_acc: 0.7233\n",
            "Epoch 31/5000\n",
            "50000/50000 [==============================] - 33s 652us/step - loss: 0.7888 - acc: 0.7229 - val_loss: 0.8095 - val_acc: 0.7241\n",
            "Epoch 32/5000\n",
            "50000/50000 [==============================] - 33s 652us/step - loss: 0.7715 - acc: 0.7267 - val_loss: 0.8108 - val_acc: 0.7189\n",
            "Epoch 33/5000\n",
            "50000/50000 [==============================] - 33s 653us/step - loss: 0.7570 - acc: 0.7324 - val_loss: 0.7914 - val_acc: 0.7293\n",
            "Epoch 34/5000\n",
            "50000/50000 [==============================] - 33s 652us/step - loss: 0.7376 - acc: 0.7386 - val_loss: 0.7818 - val_acc: 0.7307\n",
            "Epoch 35/5000\n",
            "50000/50000 [==============================] - 33s 651us/step - loss: 0.7247 - acc: 0.7446 - val_loss: 0.7841 - val_acc: 0.7280\n",
            "Epoch 36/5000\n",
            "50000/50000 [==============================] - 33s 651us/step - loss: 0.7123 - acc: 0.7475 - val_loss: 0.7686 - val_acc: 0.7366\n",
            "Epoch 37/5000\n",
            "50000/50000 [==============================] - 33s 652us/step - loss: 0.6965 - acc: 0.7535 - val_loss: 0.7659 - val_acc: 0.7393\n",
            "Epoch 38/5000\n",
            "50000/50000 [==============================] - 33s 653us/step - loss: 0.6815 - acc: 0.7598 - val_loss: 0.7574 - val_acc: 0.7413\n",
            "Epoch 39/5000\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 0.6660 - acc: 0.7635 - val_loss: 0.7569 - val_acc: 0.7433\n",
            "Epoch 40/5000\n",
            "50000/50000 [==============================] - 33s 653us/step - loss: 0.6487 - acc: 0.7674 - val_loss: 0.7727 - val_acc: 0.7398\n",
            "Epoch 41/5000\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 0.6478 - acc: 0.7717 - val_loss: 0.7534 - val_acc: 0.7458\n",
            "Epoch 42/5000\n",
            "50000/50000 [==============================] - 33s 653us/step - loss: 0.6228 - acc: 0.7759 - val_loss: 0.7550 - val_acc: 0.7461\n",
            "Epoch 43/5000\n",
            "50000/50000 [==============================] - 33s 653us/step - loss: 0.6144 - acc: 0.7805 - val_loss: 0.7314 - val_acc: 0.7528\n",
            "Epoch 44/5000\n",
            "50000/50000 [==============================] - 33s 653us/step - loss: 0.6026 - acc: 0.7850 - val_loss: 0.7310 - val_acc: 0.7523\n",
            "Epoch 45/5000\n",
            "50000/50000 [==============================] - 33s 652us/step - loss: 0.5902 - acc: 0.7889 - val_loss: 0.7403 - val_acc: 0.7539\n",
            "Epoch 46/5000\n",
            "50000/50000 [==============================] - 33s 653us/step - loss: 0.5779 - acc: 0.7929 - val_loss: 0.7342 - val_acc: 0.7526\n",
            "Epoch 47/5000\n",
            "50000/50000 [==============================] - 33s 653us/step - loss: 0.5680 - acc: 0.7961 - val_loss: 0.7245 - val_acc: 0.7550\n",
            "Epoch 48/5000\n",
            "50000/50000 [==============================] - 33s 653us/step - loss: 0.5559 - acc: 0.8014 - val_loss: 0.7297 - val_acc: 0.7525\n",
            "Epoch 49/5000\n",
            "50000/50000 [==============================] - 33s 652us/step - loss: 0.5467 - acc: 0.8029 - val_loss: 0.7273 - val_acc: 0.7603\n",
            "Epoch 50/5000\n",
            "50000/50000 [==============================] - 33s 652us/step - loss: 0.5330 - acc: 0.8091 - val_loss: 0.7380 - val_acc: 0.7573\n",
            "Epoch 51/5000\n",
            "50000/50000 [==============================] - 33s 652us/step - loss: 0.5321 - acc: 0.8092 - val_loss: 0.7312 - val_acc: 0.7584\n",
            "Epoch 52/5000\n",
            "50000/50000 [==============================] - 33s 650us/step - loss: 0.5112 - acc: 0.8159 - val_loss: 0.7282 - val_acc: 0.7579\n",
            "Epoch 53/5000\n",
            "50000/50000 [==============================] - 33s 652us/step - loss: 0.5081 - acc: 0.8163 - val_loss: 0.7334 - val_acc: 0.7570\n",
            "Epoch 54/5000\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 0.4959 - acc: 0.8215 - val_loss: 0.7300 - val_acc: 0.7596\n",
            "Epoch 55/5000\n",
            "50000/50000 [==============================] - 33s 665us/step - loss: 0.4836 - acc: 0.8260 - val_loss: 0.7385 - val_acc: 0.7599\n",
            "Epoch 56/5000\n",
            "50000/50000 [==============================] - 33s 660us/step - loss: 0.4765 - acc: 0.8293 - val_loss: 0.7296 - val_acc: 0.7639\n",
            "Epoch 57/5000\n",
            "50000/50000 [==============================] - 33s 658us/step - loss: 0.4595 - acc: 0.8328 - val_loss: 0.7331 - val_acc: 0.7587\n",
            "Epoch 58/5000\n",
            "50000/50000 [==============================] - 33s 659us/step - loss: 0.4568 - acc: 0.8345 - val_loss: 0.7229 - val_acc: 0.7679\n",
            "Epoch 59/5000\n",
            "50000/50000 [==============================] - 33s 658us/step - loss: 0.4447 - acc: 0.8385 - val_loss: 0.7537 - val_acc: 0.7640\n",
            "Epoch 60/5000\n",
            "50000/50000 [==============================] - 33s 658us/step - loss: 0.4365 - acc: 0.8434 - val_loss: 0.7472 - val_acc: 0.7637\n",
            "Epoch 61/5000\n",
            "50000/50000 [==============================] - 33s 658us/step - loss: 0.4347 - acc: 0.8430 - val_loss: 0.7413 - val_acc: 0.7622\n",
            "Epoch 62/5000\n",
            "50000/50000 [==============================] - 33s 659us/step - loss: 0.4257 - acc: 0.8461 - val_loss: 0.7417 - val_acc: 0.7601\n",
            "Epoch 63/5000\n",
            "50000/50000 [==============================] - 33s 660us/step - loss: 0.4132 - acc: 0.8505 - val_loss: 0.7263 - val_acc: 0.7693\n",
            "Epoch 64/5000\n",
            "50000/50000 [==============================] - 33s 668us/step - loss: 0.4065 - acc: 0.8522 - val_loss: 0.7289 - val_acc: 0.7680\n",
            "Epoch 65/5000\n",
            "50000/50000 [==============================] - 33s 666us/step - loss: 0.4017 - acc: 0.8562 - val_loss: 0.7387 - val_acc: 0.7679\n",
            "Epoch 66/5000\n",
            "50000/50000 [==============================] - 33s 662us/step - loss: 0.3936 - acc: 0.8558 - val_loss: 0.7311 - val_acc: 0.7668\n",
            "Epoch 67/5000\n",
            "50000/50000 [==============================] - 33s 663us/step - loss: 0.3841 - acc: 0.8614 - val_loss: 0.7365 - val_acc: 0.7678\n",
            "Epoch 68/5000\n",
            "50000/50000 [==============================] - 33s 664us/step - loss: 0.3794 - acc: 0.8607 - val_loss: 0.7491 - val_acc: 0.7646\n",
            "Epoch 69/5000\n",
            "50000/50000 [==============================] - 33s 662us/step - loss: 0.3784 - acc: 0.8627 - val_loss: 0.7458 - val_acc: 0.7665\n",
            "Epoch 70/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.3648 - acc: 0.8676 - val_loss: 0.7518 - val_acc: 0.7702\n",
            "Epoch 71/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.3633 - acc: 0.8677 - val_loss: 0.7572 - val_acc: 0.7725\n",
            "Epoch 72/5000\n",
            "50000/50000 [==============================] - 33s 662us/step - loss: 0.3531 - acc: 0.8715 - val_loss: 0.7594 - val_acc: 0.7725\n",
            "Epoch 73/5000\n",
            "50000/50000 [==============================] - 33s 663us/step - loss: 0.3507 - acc: 0.8721 - val_loss: 0.7612 - val_acc: 0.7692\n",
            "Epoch 74/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.3442 - acc: 0.8737 - val_loss: 0.7675 - val_acc: 0.7742\n",
            "Epoch 75/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.3346 - acc: 0.8781 - val_loss: 0.7543 - val_acc: 0.7732\n",
            "Epoch 76/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.3302 - acc: 0.8791 - val_loss: 0.7596 - val_acc: 0.7733\n",
            "Epoch 77/5000\n",
            "50000/50000 [==============================] - 33s 660us/step - loss: 0.3271 - acc: 0.8809 - val_loss: 0.7590 - val_acc: 0.7730\n",
            "Epoch 78/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.3179 - acc: 0.8835 - val_loss: 0.7680 - val_acc: 0.7717\n",
            "Epoch 79/5000\n",
            "50000/50000 [==============================] - 33s 660us/step - loss: 0.3198 - acc: 0.8845 - val_loss: 0.7689 - val_acc: 0.7732\n",
            "Epoch 80/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.3132 - acc: 0.8855 - val_loss: 0.7710 - val_acc: 0.7749\n",
            "Epoch 81/5000\n",
            "50000/50000 [==============================] - 33s 660us/step - loss: 0.3072 - acc: 0.8894 - val_loss: 0.7538 - val_acc: 0.7752\n",
            "Epoch 82/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.3050 - acc: 0.8890 - val_loss: 0.7896 - val_acc: 0.7695\n",
            "Epoch 83/5000\n",
            "50000/50000 [==============================] - 33s 659us/step - loss: 0.2913 - acc: 0.8945 - val_loss: 0.7817 - val_acc: 0.7746\n",
            "Epoch 84/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.2922 - acc: 0.8932 - val_loss: 0.7731 - val_acc: 0.7762\n",
            "Epoch 85/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.2905 - acc: 0.8942 - val_loss: 0.7936 - val_acc: 0.7764\n",
            "Epoch 86/5000\n",
            "50000/50000 [==============================] - 33s 662us/step - loss: 0.2871 - acc: 0.8954 - val_loss: 0.7795 - val_acc: 0.7735\n",
            "Epoch 87/5000\n",
            "50000/50000 [==============================] - 33s 662us/step - loss: 0.2837 - acc: 0.8984 - val_loss: 0.7948 - val_acc: 0.7774\n",
            "Epoch 88/5000\n",
            "50000/50000 [==============================] - 33s 660us/step - loss: 0.2773 - acc: 0.8991 - val_loss: 0.7912 - val_acc: 0.7748\n",
            "Epoch 89/5000\n",
            "50000/50000 [==============================] - 33s 659us/step - loss: 0.2726 - acc: 0.9010 - val_loss: 0.7995 - val_acc: 0.7740\n",
            "Epoch 90/5000\n",
            "50000/50000 [==============================] - 33s 659us/step - loss: 0.2669 - acc: 0.9029 - val_loss: 0.7981 - val_acc: 0.7771\n",
            "Epoch 91/5000\n",
            "50000/50000 [==============================] - 33s 660us/step - loss: 0.2694 - acc: 0.9018 - val_loss: 0.8030 - val_acc: 0.7761\n",
            "Epoch 92/5000\n",
            "50000/50000 [==============================] - 33s 662us/step - loss: 0.2665 - acc: 0.9030 - val_loss: 0.8034 - val_acc: 0.7753\n",
            "Epoch 93/5000\n",
            "50000/50000 [==============================] - 33s 662us/step - loss: 0.2594 - acc: 0.9055 - val_loss: 0.8071 - val_acc: 0.7763\n",
            "Epoch 94/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.2518 - acc: 0.9093 - val_loss: 0.8137 - val_acc: 0.7767\n",
            "Epoch 95/5000\n",
            "50000/50000 [==============================] - 33s 662us/step - loss: 0.2528 - acc: 0.9073 - val_loss: 0.8296 - val_acc: 0.7728\n",
            "Epoch 96/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.2507 - acc: 0.9096 - val_loss: 0.8262 - val_acc: 0.7739\n",
            "Epoch 97/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.2430 - acc: 0.9122 - val_loss: 0.8187 - val_acc: 0.7760\n",
            "Epoch 98/5000\n",
            "50000/50000 [==============================] - 33s 657us/step - loss: 0.2470 - acc: 0.9105 - val_loss: 0.8070 - val_acc: 0.7781\n",
            "Epoch 99/5000\n",
            "50000/50000 [==============================] - 33s 661us/step - loss: 0.2376 - acc: 0.9137 - val_loss: 0.8203 - val_acc: 0.7779\n",
            "Epoch 100/5000\n",
            "50000/50000 [==============================] - 33s 660us/step - loss: 0.2345 - acc: 0.9157 - val_loss: 0.8208 - val_acc: 0.7760\n",
            "Epoch 101/5000\n",
            " 7296/50000 [===>..........................] - ETA: 26s - loss: 0.2174 - acc: 0.9200"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gmieP_qaZS5y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XJpNZBOfmU-O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IKZDZJmNB2X1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PC7TEBnnSbdb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}